{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using style of 'Solarize_Light2' to plot\n",
      "All traditional libs imported properly!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time, datetime\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import missingno\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mpl.style.use(['Solarize_Light2'])\n",
    "print(\"Using style of 'Solarize_Light2' to plot\")\n",
    "\n",
    "\n",
    "# Plot the Figures Inline\n",
    "%matplotlib inline\n",
    "\n",
    "print('All traditional libs imported properly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask lib dependencies imported properly!\n"
     ]
    }
   ],
   "source": [
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "import dask.delayed as delayed\n",
    "\n",
    "print('Dask lib dependencies imported properly!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **DATA GATHERING MECHANISM**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we start our exploration of Dask by addressing some necessary background knowledge for **data gathering**. More specifically, we’ll\n",
    "look at how Dask DataFrames are well suited to manipulate structured data,\n",
    "which is data that consists of rows and columns. We’ll also look at how Dask\n",
    "can support parallel processing and handle large datasets by chunking data\n",
    "into smaller pieces called **partitions**. Plus, we’ll look at some performance maximizing best practices throughout the chapter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The importance of **indices** in Dask cannot be overstated: they hold the\n",
    "key to distributing DataFrame workloads across clusters of machines. With\n",
    "that in mind, let's take a look at how indices are used to form **partitions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas is a very popular and powerful framework\n",
    "for analyzing structured data, but its biggest limitation is that it was not\n",
    "designed with scalability in mind. Pandas is exceptionally well suited for\n",
    "handling small structured datasets and is highly optimized to perform fast\n",
    "and efficient operations on data stored in memory. This is where Dask’s DataFrame API\n",
    "comes in: by providing a wrapper around Pandas that intelligently splits huge\n",
    "data frames into smaller pieces and spreads them across a cluster of workers,\n",
    "operations on huge datasets can be completed much more quickly and\n",
    "robustly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different pieces of the DataFrame that Dask oversees are called\n",
    "**partitions**. Each partition is a relatively small DataFrame that can be\n",
    "dispatched to any worker and maintains its full lineage in case it must be\n",
    "reproduced. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between how Pandas would handle\n",
    "the dataset and how Dask would handle the dataset: Using Pandas, the\n",
    "dataset would be loaded into memory and worked on sequentially one row at\n",
    "a time. Dask, on the other hand, can split the data into multiple partitions,\n",
    "allowing the workload to be **parallelized**. This means if we had a longrunning function to apply over the DataFrame, Dask could complete the\n",
    "work more efficiently by spreading the work out over multiple machines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since partitioning can have such a significant impact on performance, you\n",
    "might be worried that managing partitioning will be a difficult and tedious\n",
    "part of constructing Dask workloads. However, fear not: Dask tries to help\n",
    "you get as much performance as possible without manual tuning by\n",
    "including some sensible defaults and heuristics for creating and managing\n",
    "partitions. For example, when reading in data using the read_csv method of\n",
    "Dask DataFrames, the default partition size is 64 MB each (this is also\n",
    "known as the default _blocksize_). While 64 MB might seem quite small given\n",
    "that modern servers tend to have tens of gigabytes of RAM, it is an amount\n",
    "of data that is small enough that it can be quickly transported over the\n",
    "network if necessary, but large enough to minimize the likelihood that a\n",
    "machine will run out of things to do while waiting for the next partition to\n",
    "arrive. Using either the default or a user-specified blocksize, the data will be\n",
    "split into as many partitions as necessary so that each partition is no larger\n",
    "than the blocksize. If you desire to create a DataFrame with a specific\n",
    "number of partitions instead, you can specify that when creating the\n",
    "DataFrame by passing in the **npartitions** argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_IDs = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "person_last_names = ['Smith', 'Williams',\n",
    "                     'Williams','Jackson',\n",
    "                     'Johnson','Smith',\n",
    "                     'Anderson','Christiansen',\n",
    "                     'Carter','Davidson']\n",
    "\n",
    "person_first_names = ['John', 'Bill',\n",
    "                      'Jane','Cathy',\n",
    "                      'Stuart','James',\n",
    "                      'Felicity','Liam',\n",
    "                      'Nancy','Christina']\n",
    "\n",
    "person_DOBs = ['1982-10-06', '1990-07-04', '1989-05-06', '1974-01-24', '1995-06-05', \n",
    "               '1984-04-16', '1976-09-15', '1992-10-02', '1986-02-05', '1993-08-11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.DataFrame({'Person ID':person_IDs,\n",
    "                        'Last Name': person_last_names,\n",
    "                        'First Name': person_first_names,\n",
    "                        'Date of Birth': person_DOBs},\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>John</td>\n",
       "      <td>1982-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Bill</td>\n",
       "      <td>1990-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Jane</td>\n",
       "      <td>1989-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>1974-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Stuart</td>\n",
       "      <td>1995-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Smith</td>\n",
       "      <td>James</td>\n",
       "      <td>1984-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>1976-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Christiansen</td>\n",
       "      <td>Liam</td>\n",
       "      <td>1992-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Carter</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>1986-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>Christina</td>\n",
       "      <td>1993-08-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Person ID     Last Name First Name Date of Birth\n",
       "0          1         Smith       John    1982-10-06\n",
       "1          2      Williams       Bill    1990-07-04\n",
       "2          3      Williams       Jane    1989-05-06\n",
       "3          4       Jackson      Cathy    1974-01-24\n",
       "4          5       Johnson     Stuart    1995-06-05\n",
       "5          6         Smith      James    1984-04-16\n",
       "6          7      Anderson   Felicity    1976-09-15\n",
       "7          8  Christiansen       Liam    1992-10-02\n",
       "8          9        Carter      Nancy    1986-02-05\n",
       "9         10      Davidson  Christina    1993-08-11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_2 = pd.DataFrame([person_IDs,\n",
    "                    person_last_names,\n",
    "                    person_first_names,\n",
    "                    person_DOBs],\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_2 = pdf_2.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_2.columns = ['Person ID', 'Last Name', 'First Name', 'Date of Birth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Smith</td>\n",
       "      <td>John</td>\n",
       "      <td>1982-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Bill</td>\n",
       "      <td>1990-07-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Williams</td>\n",
       "      <td>Jane</td>\n",
       "      <td>1989-05-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Jackson</td>\n",
       "      <td>Cathy</td>\n",
       "      <td>1974-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Johnson</td>\n",
       "      <td>Stuart</td>\n",
       "      <td>1995-06-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Smith</td>\n",
       "      <td>James</td>\n",
       "      <td>1984-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Anderson</td>\n",
       "      <td>Felicity</td>\n",
       "      <td>1976-09-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Christiansen</td>\n",
       "      <td>Liam</td>\n",
       "      <td>1992-10-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Carter</td>\n",
       "      <td>Nancy</td>\n",
       "      <td>1986-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Davidson</td>\n",
       "      <td>Christina</td>\n",
       "      <td>1993-08-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Person ID     Last Name First Name Date of Birth\n",
       "0         1         Smith       John    1982-10-06\n",
       "1         2      Williams       Bill    1990-07-04\n",
       "2         3      Williams       Jane    1989-05-06\n",
       "3         4       Jackson      Cathy    1974-01-24\n",
       "4         5       Johnson     Stuart    1995-06-05\n",
       "5         6         Smith      James    1984-04-16\n",
       "6         7      Anderson   Felicity    1976-09-15\n",
       "7         8  Christiansen       Liam    1992-10-02\n",
       "8         9        Carter      Nancy    1986-02-05\n",
       "9        10      Davidson  Christina    1993-08-11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_1 = dd.from_pandas(pdf, npartitions = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 1 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Person ID Last Name First Name Date of Birth\n",
       "npartitions=1                                             \n",
       "0                 int64    object     object        object\n",
       "9                   ...       ...        ...           ...\n",
       "Dask Name: from_pandas, 1 tasks"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFMAAAA7CAYAAAAHFbY3AAAABmJLR0QA/wD/AP+gvaeTAAACCUlEQVR4nO3cv4riUBSA8W+WwVYrQZFU9oqFYGtjlZSCDxAIzBaylY8i6YIogoVgnkAYFHwIixQidmmslGyxrDCjzh84O7mZPT+4zb3N4cNEUclDkiQJSsLPH2lP8J1oTEEaU9Dj643T6cRiseB8PqcxTyZUKhVardb1QfLKfD5PAF3vrBueri7z4/H4N7KuG2s8Ht97weo9U5LGFKQxBWlMQRpTkMYUpDEFaUxBGlOQxhSkMQVpTEEaU5DGFKQxBRkdMwxDHMfBcRzCMEx7nHdd/Wxhiul0ymQyYTQaATAYDNjv97ium/Jk9xkZM4oier0e6/WafD4PgOd51Ot1ms0mtVot5QlvM/IyX61WAJTL5cteqVQCYLPZpDLTRxgZc7lcAmBZ1mWvWCwCGH3vNDLmcDi8e6Yx/xNGxrRt++6Z53lfOMnnGB3zcDhc9qIoAqDRaKQy00cYGbPT6QCw3W4ve7vd7sWZiYyMaVkWvu8TBAFxHBPHMUEQ4Pv+i3d40xj5oR3AdV3CMKRQKGDbNv1+n3a7nfZYbzI2Jvy5d2bpj81GXuZZpTEFaUxBGlOQxhSkMQVpTEEaU5DGFKQxBWlMQRpTkMYUpDEFaUxBGlOQxhR095v22Wz2lXNkxltdrmJWq1UAut3uv5so43K53M39B316jBh9eowkjSlIYwp6BH6lPcQ38fwbVvquo8GE91QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_2 = dd.from_pandas(pdf, npartitions = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 2 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Person ID Last Name First Name Date of Birth\n",
       "npartitions=2                                             \n",
       "0                 int64    object     object        object\n",
       "5                   ...       ...        ...           ...\n",
       "9                   ...       ...        ...           ...\n",
       "Dask Name: from_pandas, 2 tasks"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALMAAAA7CAYAAAAw97tGAAAABmJLR0QA/wD/AP+gvaeTAAACj0lEQVR4nO3cv0pycRzH8Y8P4aqToIi3kDQIri5Nnt0LEIQa5Jnaa/QCRCcRJWgQPFcgPGh5EQ0OEW5naSrOMwSC/yrEOr/z7f2CA3VOxJcv7+FHcUyEYRgKiL/LP1FPABwLMcMMYoYZJ5s3Xl9fNR6P9fb2FsU8sZDP51Uul7/ld7P/z+3df7hhNBqFkrg+ub4L+z94/xdbx4yXlxfp/ae5dlyDwWBzZUfF/g/fP2dmmEHMMIOYYQYxwwxihhnEDDOIGWYQM8wgZphBzDCDmGEGMcMMYoYZxAwziBlmOB2z7/vyPE+e58n3/ajH+VWCIND9/b263a48z4t6nC/Zem3KFbe3txoOh+r3+5Kkq6srPT8/q16vRzzZ79BqtSRJNzc3EU/ydU7GvFgsVKvVNJvNlEqlJEmNRkPFYlGlUkmnp6cRT2jf9fW1pHjF7OQxYzqdSpJyudzqXjablSTN5/NIZoL7nIx5MplIkgqFwupeJpORJM7O2MvJmNvt9t5nxIx9nIwZOISTMVer1b3PGo3GD06COHE65uVyubq3WCwkSWdnZ5HMBPc5GfP5+bkk6fHxcXXv6elp7RmwycmYC4WCOp2Oer2egiBQEATq9XrqdDprf+HA9wqCYOfXrnLynyaSVK/X5fu+0um0qtWqms2mKpVK1GP9GolEYu37dDot6f1jw1zlbMzS+9nZ5eVZFse9O3nMAA5BzDCDmGEGMcMMYoYZxAwziBlmEDPMIGaYQcwwg5hhBjHDDGKGGcQMM4gZZhAzzCBmmLH3TZO7u7ufnCM2fmov7H+3D/cSbnh4eAglcX1wJZPJzbUdDfs/eP8XiTCOL3sB2y45M8MMYoYZxAwzTiT9jXoI4Aj+/QcNv2DsD+W6xAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 5, 9)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_3 = dd.from_pandas(pdf, npartitions = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=3</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from_pandas, 3 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Person ID Last Name First Name Date of Birth\n",
       "npartitions=3                                             \n",
       "0                 int64    object     object        object\n",
       "4                   ...       ...        ...           ...\n",
       "8                   ...       ...        ...           ...\n",
       "9                   ...       ...        ...           ...\n",
       "Dask Name: from_pandas, 3 tasks"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARMAAAA7CAYAAABYIW5XAAAABmJLR0QA/wD/AP+gvaeTAAADiUlEQVR4nO3dMUhqfRjH8d95ubTqFBTh2hpNtRTUEATHufYU5d4hLk0tDa4NbYZOIoHQECQ1RVC8RAUNZ2htcGhw6ixNhe8Q15e8afdyH/3/vX4/8Ic6Rjw8xRf1QAWtVqslAPgz3/5xPQGAvwMxAWCCmAAw8aXzwsvLi46Pj/X6+upinqEwNTWl+fn5vnxv9v859u9W1/23OhwdHbUkcT45/cL+2f8wnA98/ellzvPzs/T21ZwPzsHBQefKTLF/9u/z6bV/3jMBYIKYADBBTACYICYATBATACaICQATxASACWICwAQxAWCCmAAwQUwAmCAmAEwQEwAmiAkAE8QEgAmvY1Kv15VOp5VOp1Wv112PM1LiONb19bXK5bLS6bTrcUZOo9FQPp9XEATK5/M6Pz93PdKnvI1JrVZTuVxWtVpVtVrV6empyuWy67FGxu7urk5OTpTNZgn5gMVxrCiKVCwW9fT0pMXFRS0vL3v/c/AyJo1GQ+vr69re3lYikVAikVAul1M2m1UURa7HGwmFQkGFQsH1GCPp8vJSYRhKkhKJhNbW1iTJ+2eIXsbk6upKkjQ5Odm+NjExIUm6vb11MhMwKD9C0imXyw14kt/jZUwuLi4kSalUqn1tfHxckrx/qgdYi+NYkrS6uup4kt68jMn+/n7Xx4gJRs3d3Z3CMNTCwoLrUXryMiYA/re3t9d+/9BnXsak22tGyf/XjYClWq2mMAw1NzfnepRPeR2TZrPZvtZoNCRJs7OzTmYCBi2KIt3f3yuTybge5Zd4GZOVlRVJ0sPDQ/va4+Pju8eAv1mz2dTZ2dm72/NRFCmfzzucqjcvY5JKpVQqlVSpVBTHseI4VqVSUalUeneHB/314y5C58for2azqY2NDW1tbSkIgvaZmZnx+o7OT/+43BeZTEb1el3JZFJhGGpzc1NLS0uuxxoZQRC8+zyZTEp6+7eZ6K+dnZ2udy2np6cHPM2v8zYm0tt7J/zyusHe3SkWiyoWi67H+G1evswBMHyICQATxASACWICwAQxAWCCmAAwQUwAmCAmAEwQEwAmiAkAE8QEgAliAsAEMQFggpgAMEFMAJggJgBMEBMAJrr+pbXDw8NBzjE0BrUX9v8x9u9Wz720Otzc3LQkcXqcsbGxzrWZYf/s3/fTZf9fg1aLP/YJ4I994z0TACaICQATxASAiS+SvrseAsDQ+/c/lpzaFVpD4wIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_3.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 4, 8, 9)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_3.divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_3.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple useful attributes of Dask DataFrames that can be\n",
    "used to inspect how a DataFrame is partitioned. The first attribute,\n",
    "**divisions**, (0, 5, 9), shows the boundaries of the partitioning scheme\n",
    "(remember that partitions are created on the index). This might look strange\n",
    "since there are two partitions but three boundaries. Each partition’s\n",
    "boundary consists of pairs of numbers from the list of divisions. The\n",
    "boundary for the first partition is “from 0 up to (but not including) 5,”\n",
    "meaning it will contain rows 0, 1, 2, 3, and 4. The boundary for the second\n",
    "partition is “from 5 through (and including) 9,” meaning it will contain rows\n",
    "5, 6, 7, 8, and 9. The last partition always includes the upper boundary,\n",
    "whereas the other partitions go up to but don’t include their upper boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second attribute, **npartitions**, simply returns the number of partitions\n",
    "that exist in the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **map_partitions( )** method to count the\n",
    "number of rows in each partition. map_partitions generally applies a given\n",
    "function to each partition. This means that the result of the map_partitions\n",
    "call will return a Series equal in size to the number of partitions the\n",
    "DataFrame currently has. Since ddf_2 has two partitions in this DataFrame, we\n",
    "get two items back in the result of the call. The output shows that each\n",
    "partition contains five rows, meaning Dask split the DataFrame into two\n",
    "equal pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=1\n",
       "0    int64\n",
       "9      ...\n",
       "dtype: int64\n",
       "Dask Name: len, 2 tasks"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1.map_partitions(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_1.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_2.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_3.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it may be necessary to change the number of partitions in a\n",
    "Dask DataFrame. Particularly when your computations include a substantialamount of filtering, the size of each partition can become imbalanced, which\n",
    "can have negative performance consequences on subsequent computations.\n",
    "The reason for this is because if one partition suddenly contains a majority of\n",
    "the data, all the advantages of parallelism are effectively lost.\n",
    "Let’s look at an\n",
    "example of this. First, we’ll derive a new DataFrame by applying a filter to\n",
    "our original DataFrame that removes all people with the last name Williams.\n",
    "We’ll then inspect the makeup of the new DataFrame by using the same\n",
    "map_partitions call to count the rows per partition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_filtered = ddf_2[ddf_2['Last Name'] != 'Williams']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: getitem, 8 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Person ID Last Name First Name Date of Birth\n",
       "npartitions=2                                             \n",
       "0                 int64    object     object        object\n",
       "5                   ...       ...        ...           ...\n",
       "9                   ...       ...        ...           ...\n",
       "Dask Name: getitem, 8 tasks"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_filtered.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_filtered_reduced = ddf_filtered.repartition(npartitions = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Person ID</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Date of Birth</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=1</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: repartition, 9 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              Person ID Last Name First Name Date of Birth\n",
       "npartitions=1                                             \n",
       "0                 int64    object     object        object\n",
       "9                   ...       ...        ...           ...\n",
       "Dask Name: repartition, 9 tasks"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_filtered_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_filtered_reduced.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice what happened: the first partition now only contains three rows, and\n",
    "the second partition has the original five. People with the last name of\n",
    "Williams happened to be in the first partition, so our new DataFrame has\n",
    "become rather unbalanced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second two lines of code in the listing aim to fix the imbalance by\n",
    "using the repartition method on the filtered DataFrame. The npartitions\n",
    "argument here works the same way as the npartitions argument used\n",
    "earlier when we created the initial DataFrame. Simply specify the number of\n",
    "partitions you want and Dask will figure out what needs to be done to make\n",
    "it so. If you specify a lower number than the current number of partitions,\n",
    "Dask will combine existing partitions by concatenation. If you specify a\n",
    "higher number than the current number of partitions, Dask will split existing\n",
    "partitions into smaller pieces. You can call repartition at any time in your\n",
    "program to initiate this process. However, like all other Dask operations, it’s\n",
    "a **lazy computation**. No data will actually get moved around until you make a\n",
    "call such as **compute**, **head**, and so on. Calling the map_partitions function\n",
    "again on the new DataFrame, we can see that the number of partitions has\n",
    "been reduced to one, and it contains all eight of the rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **SHUFFLE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In\n",
    "distributed computing, the shuffle is the process of broadcasting all\n",
    "partitions to all workers. Shuffling the data is necessary when performing\n",
    "sorting, grouping, and indexing operations, because each row needs to be\n",
    "compared to every other row in the entire DataFrame to determine its correct\n",
    "relative position. This is a time-expensive operation, because it necessitates\n",
    "transferring large amounts of data over the network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ddf_2, we'll see what would happen with our DataFrame if we\n",
    "want to group our data by Last Name. For example, we might want to find\n",
    "the eldest person by last name. For the majority of the data, it’s no problem.\n",
    "Most of the last names in this dataset are unique. As you can see in ddf_2, there are only two cases in which we have multiple people with\n",
    "the same last name: Williams and Smith. For the two people named\n",
    "Williams, they are in the same partition, so server 1 has all the information it\n",
    "needs locally to determine that the oldest Williams was born in 1989.\n",
    "However, for the people named Smith, there’s one Smith in partition 1 and\n",
    "one Smith in partition 2. Either server 1 will have to send its Smith to server\n",
    "2 to make the comparison, or server 2 will have to send server 1 its Smith. In\n",
    "both cases, for Dask to be able to compare the birthdates of each Smith, one\n",
    "of them will have to be shipped over the network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on what needs to be done with the data, completely avoiding\n",
    "shuffle operations might not be feasible. However, you can do a few things to\n",
    "minimize the need for shuffling the data. **First**, ensuring that the data is\n",
    "stored in a presorted order will eliminate the need to sort the data with Dask.\n",
    "If possible, sorting the data in a source system, such as a relational database,\n",
    "can be faster and more efficient than sorting the data in a distributed system.\n",
    "**Second**, using a sorted column as the DataFrame’s index will enable greater\n",
    "efficiency with joins. When the data is presorted, lookup operations are very\n",
    "fast because the partition where a certain row is kept can be easily\n",
    "determined by using the divisions defined on the DataFrame. **Finally**, if you\n",
    "must use an operation that triggers a shuffle, persist the result if you have\n",
    "the resources to do so. This will prevent having to repeat shuffling the data\n",
    "again if the DataFrame needs to be recomputed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **LIMITATIONS OF DASK DATAFRAMEs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First** and foremost, Dask DataFrames do not expose the entire Pandas API.\n",
    "Even though Dask DataFrames are made up of smaller Pandas DataFrames,\n",
    "some functions that Pandas does well are simply not conducive to a\n",
    "distributed environment. For example, functions that would alter the\n",
    "structure of the DataFrame, such as insert and pop, are not supported\n",
    "because Dask DataFrames are immutable. Some of the more complex\n",
    "window operations are also not supported, such as expanding and EWM\n",
    "methods, as well as complex transposition methods like stack/unstack and\n",
    "melt, because of their tendency to cause a lot of data shuffling. Oftentimes,\n",
    "these expensive operations don’t really need to be performed on the full, raw\n",
    "dataset. In those cases, you should use Dask to do all your normal data prep,\n",
    "filtering, and transformation, then dump the final dataset into Pandas. You\n",
    "will then be able to perform the expensive operations on the reduced dataset.\n",
    "Dask’s DataFrame API makes it very easy to interoperate with Pandas\n",
    "DataFrames, so this pattern can be very useful when analyzing data using\n",
    "Dask DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **second** limitation is with relational-type operations, such as\n",
    "join/merge, groupby, and rolling. Although these operations are supported,\n",
    "they are likely to involve a lot of shuffling, making them performance\n",
    "bottlenecks. This can be minimized, again, either by using Dask to prepare a\n",
    "smaller dataset that can be dumped into Pandas, or by limiting these\n",
    "operations to only use the index. For example, if we wanted to join a\n",
    "DataFrame of people to a DataFrame of transactions, that computationwould be significantly faster if both datasets were sorted and indexed by the\n",
    "Person ID. This would minimize the likelihood that each person’s records are\n",
    "spread out across many partitions, in turn making shuffles more efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Third**, indexing has a few challenges due to the distributed nature of Dask.\n",
    "If you wish to use a column in a DataFrame as an index in lieu of the default\n",
    "numeric index, it will need to be sorted. If the data is stored presorted, this\n",
    "becomes no problem at all. If the data is not presorted, it can be very slow to\n",
    "sort the entire DataFrame because it requires a lot of shuffling. Effectively,\n",
    "each partition first needs to be sorted, then needs to be merged and sorted\n",
    "again with every other partition. Sometimes it may be necessary to do this,\n",
    "but if you can proactively store your data presorted for the computations you\n",
    "need, it will save you a lot of time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **other** significant difference you may notice with indexing is how Dask\n",
    "handles the reset_index method. Unlike Pandas, where this will recalculate\n",
    "a new sequential index across the entire DataFrame, the method in Dask\n",
    "DataFrames behaves like a map_partitions call. This means that each\n",
    "partition will be given its own sequential index that starts at 0, so the whole\n",
    "DataFrame will no longer have a unique sequential index."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ddf_2, each partition contained five rows, so once we called reset_index, the index\n",
    "of the first five rows remains the same, but the next five rows, which are\n",
    "contained in the next partition, start over at 0. Unfortunately, there’s no easy\n",
    "way to reset the index in a partition-aware way. Therefore, use the\n",
    "reset_index method carefully and only if you don’t plan to use the resulting\n",
    "sequential index to join, group, or sort the DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally**, since a Dask DataFrame is made up of many Pandas DataFrames,\n",
    "operations that are inefficient in Pandas will also be inefficient in Dask. For\n",
    "example, iterating over rows by using the apply and iterrows methods is\n",
    "notoriously inefficient in Pandas. Therefore, following Pandas best practices\n",
    "will give you the best performance possible when using Dask DataFrames."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
